creating GPT from scratch using BigramLanguageModel and multi head attention (Encoder block only) using attention is all you need paper
